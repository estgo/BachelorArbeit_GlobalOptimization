{
 "cells": [
  {
   "cell_type": "code",
   "id": "a0edc860",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T08:59:25.027022Z",
     "start_time": "2024-07-31T08:59:21.424588Z"
    }
   },
   "source": [
    "import os\n",
    "import math\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from botorch.acquisition import qExpectedImprovement, qLogExpectedImprovement\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.generation import MaxPosteriorSampling\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.test_functions import Ackley\n",
    "from botorch.utils.transforms import unnormalize\n",
    "from torch.quasirandom import SobolEngine\n",
    "from botorch.test_functions import SyntheticTestFunction\n",
    "from botorch.settings import debug\n",
    "\n",
    "from abc import ABC\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from botorch.exceptions.errors import InputDataError\n",
    "from botorch.test_functions.base import BaseTestProblem, ConstrainedBaseTestProblem\n",
    "from botorch.test_functions.utils import round_nearest\n",
    "\n",
    "\n",
    "\n",
    "# Constrained Max Posterior Sampling s a new sampling class, similar to MaxPosteriorSampling,\n",
    "# which implements the constrained version of Thompson Sampling described in [1].\n",
    "from botorch.generation.sampling import ConstrainedMaxPosteriorSampling\n",
    "from botorch.models.model_list_gp_regression import ModelListGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "\n",
    "\n",
    "import gpytorch\n",
    "from gpytorch.constraints import Interval\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")\n",
    "\n",
    "tkwargs = {\n",
    "    \"dtype\": torch.double,\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Change to 'cuda' if using GPU\n",
    "}\n",
    "\n",
    "print(device)\n",
    "print(tkwargs)\n"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "68c9f66d",
   "metadata": {},
   "source": [
    "min f(x) s.t. c1(x)>0 und c2(x)>0.\n",
    "\n",
    "f(x) = (1.0-x[0])* (1.0-x[0]) + 100.0 *(x[1]-x[0]*x[0])*(x[1]-x[0]*x[0])\n",
    "\n",
    "c1(x) = x[1] - x[0]*x[0]\n",
    "\n",
    "c2(x) = (x[0]-1)**3 - x[1] + 0.7\n",
    "\n",
    "\n",
    "\n",
    "-1.5 < x1< 1.5\n",
    "\n",
    "-0.5 < x2 < 2.5\n",
    "\n",
    "\n",
    "\n",
    "maximum 100 Funktionbewertungen insgesamt.\n",
    "\n",
    "\n",
    "Plot Raster, turbo visualisieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b14352d",
   "metadata": {},
   "source": [
    "### Our Function"
   ]
  },
  {
   "cell_type": "code",
   "id": "ee3c4b37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T08:59:25.137941Z",
     "start_time": "2024-07-31T08:59:25.027022Z"
    }
   },
   "source": [
    "def f(X, negate):\n",
    "    result = (1.0 - X[0])**2 + 100.0*((X[1]-X[0]**2)**2)\n",
    "    return result if not negate else -result\n",
    "\n",
    "\n",
    "bounds = torch.tensor([\n",
    "    [-1.5, -0.5],  # Lower bounds for x1 and x2\n",
    "    [1.5, 2.5]    # Upper bounds for x1 and x2\n",
    "], dtype=torch.float, device = device)\n",
    "\n",
    "dim = 2\n",
    "lb , ub = bounds\n",
    "\n",
    "batch_size = 10\n",
    "n_init = 10\n",
    "max_cholesky_size = float(\"inf\")  # Always use Cholesky\n",
    "\n",
    "def eval_objective(x):\n",
    "    \"\"\"This is a helper function we use to unnormalize and evalaute a point\"\"\"\n",
    "    \n",
    "    return f(unnormalize(x.to(device), bounds) , True)"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ab240f47",
   "metadata": {},
   "source": [
    "# Constrain Functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "5607d583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T08:59:25.143965Z",
     "start_time": "2024-07-31T08:59:25.137941Z"
    }
   },
   "source": [
    "def c1(x):  # Equivalent to enforcing that x[1] - x[0]^2 > 0\n",
    "    return x[0]**2 - x[1]\n",
    "\n",
    "\n",
    "def c2(x):  # Equivalent to enforcing that  (x[0] - 1)^3 - x[1] + 0.7 > 0\n",
    "    return x[1] - 0.7 - (x[0] - 1)**3\n",
    "\n",
    "\n",
    "\n",
    "#TODO\n",
    "# We assume c1, c2 have same bounds as the Ackley function above\n",
    "def eval_c1(x):\n",
    "    \"\"\"This is a helper function we use to unnormalize and evalaute a point\"\"\"\n",
    "    return c1(unnormalize(x, bounds))\n",
    "\n",
    "\n",
    "def eval_c2(x):\n",
    "    \"\"\"This is a helper function we use to unnormalize and evalaute a point\"\"\"\n",
    "    return c2(unnormalize(x, bounds))\n"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7f8b45bb",
   "metadata": {},
   "source": [
    "# ScBo (Turbo based) (Keep unchanged)"
   ]
  },
  {
   "cell_type": "code",
   "id": "0181b3b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T08:59:25.203884Z",
     "start_time": "2024-07-31T08:59:25.143965Z"
    }
   },
   "source": [
    "@dataclass\n",
    "class ScboState:\n",
    "    dim: int\n",
    "    batch_size: int\n",
    "    length: float = 0.8\n",
    "    length_min: float = 0.5**7\n",
    "    length_max: float = 1.6\n",
    "    failure_counter: int = 0\n",
    "    failure_tolerance: int = float(\"nan\")  # Note: Post-initialized\n",
    "    success_counter: int = 0\n",
    "    success_tolerance: int = 10  # Note: The original paper uses 3\n",
    "    best_value: float = -float(\"inf\")\n",
    "    best_constraint_values: Tensor = torch.ones(2, **tkwargs) * torch.inf\n",
    "    restart_triggered: bool = False\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.failure_tolerance = math.ceil(max([4.0 / self.batch_size, float(self.dim) / self.batch_size]))\n",
    "        \n",
    "\n",
    "\n",
    "def get_best_index_for_batch(Y: Tensor, C: Tensor):\n",
    "    \"\"\"Return the index for the best point.\"\"\"\n",
    "    is_feas = (C <= 0).all(dim=-1)\n",
    "    if is_feas.any():  # Choose best feasible candidate\n",
    "        score = Y.clone()\n",
    "        score[~is_feas] = -float(\"inf\")\n",
    "        return score.argmax()\n",
    "    return C.clamp(min=0).sum(dim=-1).argmin()\n",
    "\n",
    "def update_tr_length(state: ScboState):\n",
    "    # Update the length of the trust region according to\n",
    "    # success and failure counters\n",
    "    # (Just as in original TuRBO paper)\n",
    "    if state.success_counter == state.success_tolerance:  # Expand trust region\n",
    "        state.length = min(2.0 * state.length, state.length_max)\n",
    "        state.success_counter = 0\n",
    "    elif state.failure_counter == state.failure_tolerance:  # Shrink trust region\n",
    "        state.length /= 2.0\n",
    "        state.failure_counter = 0\n",
    "\n",
    "    if state.length < state.length_min:  # Restart when trust region becomes too small\n",
    "        state.restart_triggered = True\n",
    "\n",
    "    return state\n",
    "\n",
    "def update_state(state, Y_next, C_next):\n",
    "    \"\"\"Method used to update the TuRBO state after each step of optimization.\n",
    "\n",
    "    Success and failure counters are updated according to the objective values\n",
    "    (Y_next) and constraint values (C_next) of the batch of candidate points\n",
    "    evaluated on the optimization step.\n",
    "\n",
    "    As in the original TuRBO paper, a success is counted whenver any one of the\n",
    "    new candidate points improves upon the incumbent best point. The key difference\n",
    "    for SCBO is that we only compare points by their objective values when both points\n",
    "    are valid (meet all constraints). If exactly one of the two points being compared\n",
    "    violates a constraint, the other valid point is automatically considered to be better.\n",
    "    If both points violate some constraints, we compare them inated by their constraint values.\n",
    "    The better point in this case is the one with minimum total constraint violation\n",
    "    (the minimum sum of constraint values)\"\"\"\n",
    "\n",
    "    # Pick the best point from the batch\n",
    "    best_ind = get_best_index_for_batch(Y=Y_next, C=C_next)\n",
    "    y_next, c_next = Y_next[best_ind], C_next[best_ind]\n",
    "\n",
    "    if (c_next <= 0).all():\n",
    "        # At least one new candidate is feasible\n",
    "        improvement_threshold = state.best_value + 1e-3 * math.fabs(state.best_value)\n",
    "        if y_next > improvement_threshold or (state.best_constraint_values > 0).any():\n",
    "            state.success_counter += 1\n",
    "            state.failure_counter = 0\n",
    "            state.best_value = y_next.item()\n",
    "            state.best_constraint_values = c_next\n",
    "        else:\n",
    "            state.success_counter = 0\n",
    "            state.failure_counter += 1\n",
    "    else:\n",
    "        # No new candidate is feasible\n",
    "        total_violation_next = c_next.clamp(min=0).sum(dim=-1)\n",
    "        total_violation_center = state.best_constraint_values.clamp(min=0).sum(dim=-1)\n",
    "        if total_violation_next < total_violation_center:\n",
    "            state.success_counter += 1\n",
    "            state.failure_counter = 0\n",
    "            state.best_value = y_next.item()\n",
    "            state.best_constraint_values = c_next\n",
    "        else:\n",
    "            state.success_counter = 0\n",
    "            state.failure_counter += 1\n",
    "\n",
    "    # Update the length of the trust region according to the success and failure counters\n",
    "    state = update_tr_length(state)\n",
    "    return state"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4deadb8f",
   "metadata": {},
   "source": [
    "# Generate Batch and Functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "d209a9d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T08:59:25.213650Z",
     "start_time": "2024-07-31T08:59:25.203884Z"
    }
   },
   "source": [
    "#Überprüfe ob random\n",
    "def get_initial_points(dim, n_pts, seed=0):\n",
    "    sobol = SobolEngine(dimension=dim, scramble=True, seed=seed)\n",
    "    X_init = sobol.draw(n=n_pts).to(dtype=dtype, device=device)\n",
    "    return X_init\n",
    "\n",
    "def generate_batch(\n",
    "    state,\n",
    "    model,  # GP model\n",
    "    X,  # Evaluated points on the domain [0, 1]^d\n",
    "    Y,  # Function values\n",
    "    C,  # Constraint values\n",
    "    batch_size,\n",
    "    n_candidates,  # Number of candidates for Thompson sampling\n",
    "    constraint_model,\n",
    "    sobol: SobolEngine,\n",
    "):\n",
    "    assert X.min() >= 0.0 and X.max() <= 1.0 and torch.all(torch.isfinite(Y))\n",
    "\n",
    "    # Create the TR bounds\n",
    "    best_ind = get_best_index_for_batch(Y=Y, C=C)\n",
    "    x_center = X[best_ind, :].clone()\n",
    "    tr_lb = torch.clamp(x_center - state.length / 2.0, 0.0, 1.0)\n",
    "    tr_ub = torch.clamp(x_center + state.length / 2.0, 0.0, 1.0)\n",
    "\n",
    "    # Thompson Sampling w/ Constraints (SCBO)\n",
    "    dim = X.shape[-1]\n",
    "    pert = sobol.draw(n_candidates).to(dtype=dtype, device=device)\n",
    "    pert = tr_lb + (tr_ub - tr_lb) * pert\n",
    "\n",
    "    # Create a perturbation mask\n",
    "    prob_perturb = min(20.0 / dim, 1.0)\n",
    "    mask = torch.rand(n_candidates, dim, **tkwargs) <= prob_perturb\n",
    "    ind = torch.where(mask.sum(dim=1) == 0)[0]\n",
    "    mask[ind, torch.randint(0, dim - 1, size=(len(ind),), device=device)] = 1\n",
    "\n",
    "    # Create candidate points from the perturbations and the mask\n",
    "    X_cand = x_center.expand(n_candidates, dim).clone()\n",
    "    X_cand[mask] = pert[mask]\n",
    "\n",
    "    # Sample on the candidate points using Constrained Max Posterior Sampling\n",
    "    constrained_thompson_sampling = ConstrainedMaxPosteriorSampling(\n",
    "        model=model, constraint_model=constraint_model, replacement=False\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        X_next = constrained_thompson_sampling(X_cand, num_samples=batch_size)\n",
    "\n",
    "    return X_next"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "24effa96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T08:59:25.459639Z",
     "start_time": "2024-07-31T08:59:25.442297Z"
    }
   },
   "source": [],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "0642a3ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T08:59:25.759398Z",
     "start_time": "2024-07-31T08:59:25.754193Z"
    }
   },
   "source": [
    "gpytorch.settings.show_progress_bars = True\n",
    "\n",
    "\n",
    "def get_fitted_model(X, Y):\n",
    "    assert not torch.isnan(X).any(), \"Training data contains NaN values\"\n",
    "    assert not torch.isnan(Y).any(), \"Training labels contain NaN values\"\n",
    "    likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
    "    covar_module = ScaleKernel(  # Use the same lengthscale prior as in the TuRBO paper\n",
    "        MaternKernel(nu=1.5, ard_num_dims=dim, lengthscale_constraint=Interval(0.005, 4.0))\n",
    "    )\n",
    "    model = SingleTaskGP(\n",
    "        X,\n",
    "        Y,\n",
    "        covar_module=covar_module,\n",
    "        likelihood=likelihood,\n",
    "        outcome_transform=Standardize(m=1),\n",
    "    )\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "    with gpytorch.settings.max_cholesky_size(max_cholesky_size):\n",
    "        fit_gpytorch_mll(mll)\n",
    "\n",
    "    return model"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "64340c7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T08:59:38.941506Z",
     "start_time": "2024-07-31T08:59:27.654625Z"
    }
   },
   "source": [
    "def search_optimum_constrained(\n",
    "    n_init,\n",
    "    generate_points_fun,\n",
    "    eval_objective_fun,\n",
    "    eval_constrain_functions,\n",
    "    state,\n",
    "    generate_batch_fun,\n",
    "    fitted_model_fun\n",
    "):\n",
    "    # Generate initial data\n",
    "    dim = state.dim\n",
    "    batch_size = state.batch_size\n",
    "    N_CANDIDATES = 30 if not SMOKE_TEST else 4\n",
    "    sobol = SobolEngine(dim, scramble=True, seed=1)\n",
    "    \n",
    "    train_X = generate_points_fun(dim, n_init)\n",
    "    train_Y = torch.tensor([eval_objective_fun(x) for x in train_X], **tkwargs).unsqueeze(-1)\n",
    "\n",
    "    '''for eval_constrain_fun in eval_constrain_functions:\n",
    "        if(i == 0):\n",
    "            C = torch.tensor([eval_constrain_fun(x) for x in train_X], **tkwargs).unsqueeze(-1)\n",
    "            i += 1\n",
    "            continue\n",
    "        C_i = torch.tensor([eval_constrain_fun(x) for x in train_X], **tkwargs).unsqueeze(-1)\n",
    "        C = torch.cat([C, C_i], dim=-1)'''\n",
    "    \n",
    "    C = [torch.tensor([eval_constrain_fun(x) for x in train_X], **tkwargs).unsqueeze(-1) for eval_constrain_fun in eval_constrain_functions]\n",
    "\n",
    "    debugging = False\n",
    "    while not state.restart_triggered and not debugging:  # Run until TuRBO converges\n",
    "        # Fit GP models for objective and constraints\n",
    "        model = fitted_model_fun(train_X, train_Y)\n",
    "        C_model = [get_fitted_model(train_X, C_i) for C_i in C]\n",
    "        \n",
    "        # Generate a batch of candidates\n",
    "        with gpytorch.settings.max_cholesky_size(max_cholesky_size):\n",
    "            X_next = generate_batch_fun(\n",
    "                state=state,\n",
    "                model=model,\n",
    "                X=train_X,\n",
    "                Y=train_Y,\n",
    "                C=torch.cat(C, dim=-1),\n",
    "                batch_size=batch_size,\n",
    "                n_candidates=N_CANDIDATES,\n",
    "                constraint_model=ModelListGP(*C_model),\n",
    "                sobol=sobol,\n",
    "        )\n",
    "        # Evaluate both the objective and constraints for the selected candidaates\n",
    "        Y_next = torch.tensor([eval_objective(x) for x in X_next], dtype=dtype, device=device).unsqueeze(-1)\n",
    "        C_next = [torch.tensor([eval_constrain_fun(x) for x in X_next], **tkwargs).unsqueeze(-1) for eval_constrain_fun in eval_constrain_functions]\n",
    "\n",
    "        # Update TuRBO state\n",
    "        state = update_state(state=state, Y_next=Y_next, C_next=torch.cat(C_next, dim=-1))\n",
    "        # Append data. Note that we append all data, even points that violate\n",
    "        # the constraints. This is so our constraint models can learn more\n",
    "        # about the constraint functions and gain confidence in where violations occur.\n",
    "        train_X = torch.cat((train_X, X_next), dim=0)\n",
    "        train_Y = torch.cat((train_Y, Y_next), dim=0)\n",
    "        for i in range(len(C_next)):\n",
    "            C[i] = torch.cat((C[i] , C_next[i]) , dim=0)\n",
    "\n",
    "        # Print current status. Note that state.best_value is always the best\n",
    "        # objective value found so far which meets the constraints, or in the case\n",
    "        # that no points have been found yet which meet the constraints, it is the\n",
    "        # objective value of the point with the minimum constraint violation.\n",
    "        if (state.best_constraint_values <= 0).all():\n",
    "            print(f\"{len(train_X)}) Best value: {state.best_value:.2e}, TR length: {state.length:.2e}\")\n",
    "        else:\n",
    "            violation = state.best_constraint_values.clamp(min=0).sum()\n",
    "            print(\n",
    "                f\"{len(train_X)}) No feasible point yet! Smallest total violation: \"\n",
    "                f\"{violation:.2e}, TR length: {state.length:.2e}\"\n",
    "            )        \n",
    "    print(\"finished\")\n",
    "    return train_X, train_Y, torch.cat(C, dim=-1)\n",
    "#testing initial:\n",
    "state = ScboState(dim, batch_size=5)\n",
    "X, Y, C = search_optimum_constrained(10, get_initial_points, eval_objective, [eval_c1, eval_c2], state, generate_batch, get_fitted_model)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "52728c26",
   "metadata": {},
   "source": [
    "# Start Turbo"
   ]
  },
  {
   "cell_type": "code",
   "id": "74322609",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T08:59:50.792261Z",
     "start_time": "2024-07-31T08:59:50.271681Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_fun(X, Y, C):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Clone Y to avoid modifying the original tensor\n",
    "    score = Y.clone()\n",
    "    \n",
    "    # Set infeasible points to -inf\n",
    "    infeasible_mask = ~(C <= 0).all(dim=-1)\n",
    "    score[infeasible_mask] = float(\"-inf\")\n",
    "    \n",
    "    # Compute the maximum accumulated value\n",
    "    fx = np.maximum.accumulate(score.cpu().numpy())\n",
    "    \n",
    "    # Plot the function values\n",
    "    plt.plot(fx, marker=\"\", lw=3)\n",
    "\n",
    "    # Plot a reference line at y=0\n",
    "    plt.plot([0, len(Y)], [0, 0], \"k--\", lw=3)\n",
    "    \n",
    "    # Set plot labels and title\n",
    "    plt.ylabel(\"Function value\", fontsize=18)\n",
    "    plt.xlabel(\"Number of evaluations\", fontsize=18)\n",
    "    plt.title(\"Our Function\", fontsize=20)\n",
    "    \n",
    "    # Set plot limits\n",
    "    plt.xlim([0, len(Y)])\n",
    "    plt.ylim([-15, 1])\n",
    "\n",
    "    # Enable grid for better visualization\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "print(len(X))\n",
    "\n",
    "plot_fun(X,Y,C)"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "567449eb",
   "metadata": {},
   "source": [
    "# Draw Result"
   ]
  },
  {
   "cell_type": "code",
   "id": "8e47b492",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T08:59:51.887294Z",
     "start_time": "2024-07-31T08:59:51.880154Z"
    }
   },
   "source": [
    "'''\n",
    "def michalewicz_10d(x, m=10):\n",
    "    \"\"\"\n",
    "    Evaluate the 10-dimensional Michalewicz function.\n",
    "    \n",
    "    Parameters:\n",
    "    x : array_like\n",
    "        Input array of 10 dimensions.\n",
    "    m : int, optional\n",
    "        Parameter m of the Michalewicz function, default is 10.\n",
    "    \n",
    "    Returns:\n",
    "    float\n",
    "        Function value.\n",
    "    \"\"\"\n",
    "    if len(x) != 10:\n",
    "        raise ValueError(\"Input vector must have 10 dimensions.\")\n",
    "    \n",
    "    term = 0\n",
    "    for i in range(10):\n",
    "        term += np.sin(x[i]) * (np.sin(((i + 1) * x[i]**2) / np.pi))**(2 * m)\n",
    "    \n",
    "    return -term\n",
    "\n",
    "\n",
    "\n",
    "bounds = torch.tensor([\n",
    "    [0, 0, 0 , 0 , 0 , 0, 0 , 0 ,0 , 0],  # Lower bounds for x1 and x2\n",
    "    [np.pi , np.pi, np.pi, np.pi, np.pi, np.pi, np.pi, np.pi ,np.pi ,np.pi]    # Upper bounds for x1 and x2\n",
    "], dtype=torch.double, device = device)\n",
    "\n",
    "dim = 10\n",
    "lb , ub = bounds\n",
    "\n",
    "batch_size = 10\n",
    "n_init = 10\n",
    "max_cholesky_size = float(\"inf\")  # Always use Cholesky\n",
    "\n",
    "def eval_objective_michale(x):\n",
    "    \"\"\"This is a helper function we use to unnormalize and evalaute a point\"\"\"\n",
    "    return michalewicz_10d(unnormalize(x.to(device), bounds) , True)\n",
    "\n",
    "\n",
    "Das Problem ist dann:\n",
    "\n",
    "min f(x)\n",
    "\n",
    "0 < x_i < np.pi, i = 1,...,10\n",
    "\n",
    "Insgesamt 300 Samples.\n",
    "\n",
    "x = get_initial_points(10, 1)\n",
    "print(x)\n",
    "print(len(x[0]))\n",
    "eval_objective_michale(x)\n",
    "\n",
    "#X, Y, C = search_optimum_constrained(10, get_initial_points, eval_objective_michale, [] , state, generate_batch, get_fitted_model)\n",
    "'''"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T08:59:58.079846Z",
     "start_time": "2024-07-31T08:59:57.829930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_function_with_points(X, start_idx, end_idx, negate=False, bestIndex = -1):\n",
    "    \"\"\"\n",
    "    Plot the function and highlight points within a given range.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Tensor containing points (Nx2) where each row is a point [X1, X2].\n",
    "    - start_idx: Starting index of the points to plot.\n",
    "    - end_idx: Ending index of the points to plot.\n",
    "    - negate: Boolean indicating whether to negate the function value.\n",
    "    \"\"\"\n",
    "    # Ensure X is on CPU\n",
    "    X_cpu = X.cpu() if X.is_cuda else X\n",
    "    \n",
    "    # Generate a grid of points\n",
    "    x = np.linspace(0, 1, 100)  # X1 values\n",
    "    y = np.linspace(0, 1, 100)  # X2 values\n",
    "    X1, Y1 = np.meshgrid(x, y)  # Create a grid\n",
    "    points = torch.tensor(np.vstack([X1.ravel(), Y1.ravel()]), dtype=torch.float32)\n",
    "\n",
    "    # Evaluate the function\n",
    "    Z = f(points, negate).detach().numpy().reshape(X1.shape)\n",
    "    \n",
    "    # Ensure indices are within bounds\n",
    "    start_idx = max(0, start_idx)\n",
    "    end_idx = min(len(X_cpu), end_idx)\n",
    "    \n",
    "    # Plot the function\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))  # Make the plot bigger\n",
    "\n",
    "    # Contour plot of the function values\n",
    "    contour = ax.contourf(X1, Y1, Z, levels=50, cmap='viridis')\n",
    "\n",
    "    # Plot the points within the given range\n",
    "    if end_idx > start_idx:\n",
    "        ax.scatter(X_cpu[start_idx:end_idx, 0].numpy(), X_cpu[start_idx:end_idx, 1].numpy(), color='red', marker='o', s=100, label='Points')\n",
    "    else:\n",
    "        print(\"Invalid range: end_idx must be greater than start_idx.\")\n",
    "        \n",
    "    i\n",
    "\n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(contour, ax=ax)\n",
    "    cbar.set_label('Function Value')\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('X1', fontsize=14)\n",
    "    ax.set_ylabel('X2', fontsize=14)\n",
    "    ax.set_title('Function Contour Plot with Points', fontsize=16)\n",
    "\n",
    "    # Add grid and legend\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "best = -8000\n",
    "index = -1\n",
    "for i in range(len(Y)):\n",
    "    if Y[i] > best:\n",
    "        best = Y[i]\n",
    "        index = i\n",
    "\n",
    "print(index)\n",
    "print(best)\n",
    "# Example usage:\n",
    "# Assuming X is already defined and may be on CUDA\n",
    "plot_function_with_points(X, 0, 100, index)"
   ],
   "id": "3dcf6d69",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T08:59:53.631240Z",
     "start_time": "2024-07-31T08:59:52.984443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Define the function\n",
    "def f(X, negate):\n",
    "    result = (1.0 - X[0])**2 + 100.0*((X[1] - X[0]**2)**2)\n",
    "    return result if not negate else -result\n",
    "\n",
    "# Generate a grid of points\n",
    "x = np.linspace(-2, 2, 100)  # X1 values\n",
    "y = np.linspace(-1, 3, 100)  # X2 values\n",
    "X1, Y1 = np.meshgrid(x, y)  # Create a grid\n",
    "points = torch.tensor(np.vstack([X1.ravel(), Y1.ravel()]), dtype=torch.float32)\n",
    "\n",
    "# Evaluate the function\n",
    "negate = False  # Change to True if you want to negate the function\n",
    "Z = f(points, negate).detach().numpy().reshape(X1.shape)\n",
    "\n",
    "# Plot the function\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(X1, Y1, Z, cmap='viridis')\n",
    "\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_zlabel('Function Value')\n",
    "ax.set_title('3D Surface Plot of the Function')\n",
    "plt.show()\n"
   ],
   "id": "5e539c421765450f",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T08:57:21.405937Z",
     "start_time": "2024-07-31T08:57:21.263952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from ipywidgets import widgets, interact\n",
    "\n",
    "def plot_frame(X, Y, frame):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Scatter plot of all points up to the current frame\n",
    "    ax.scatter(X[:frame+1, 0].numpy(), X[:frame+1, 1].numpy(), c='blue')\n",
    "    \n",
    "    # Check if we need to highlight the current point\n",
    "    if frame > 0 and Y[frame] < Y[frame - 1]:\n",
    "        ax.scatter(X[frame, 0].item(), X[frame, 1].item(), c='red', marker='s', s=100)\n",
    "    \n",
    "    # Plot a line at y=0 for reference\n",
    "    ax.plot([0, len(Y)], [0, 0], \"k--\", lw=3)\n",
    "    \n",
    "    # Set plot limits\n",
    "    ax.set_xlim([X[:, 0].min().item() - 1, X[:, 0].max().item() + 1])\n",
    "    ax.set_ylim([X[:, 1].min().item() - 1, X[:, 1].max().item() + 1])\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_ylabel(\"Y\", fontsize=18)\n",
    "    ax.set_xlabel(\"X\", fontsize=18)\n",
    "    ax.set_title(\"ScBO Animation with Trust Region\", fontsize=20)\n",
    "    \n",
    "    # Enable grid\n",
    "    ax.grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def interactive_plot(X, Y):\n",
    "    # Create an interactive widget for frame control\n",
    "    interact(lambda frame: plot_frame(X, Y, frame), frame=widgets.IntSlider(min=0, max=len(X)-1, step=1, value=0))\n",
    "\n",
    "# Example usage:\n",
    "# Assuming X is a tensor of shape (N, 2) and Y is a tensor of shape (N,)\n",
    "X = torch.rand(100, 2) * 10  # Example data points\n",
    "Y = torch.sin(X[:, 0]) - torch.cos(X[:, 1])  # Example function evaluations\n",
    "interactive_plot(X, Y)\n"
   ],
   "id": "6bbf0d8dbb4b06f0",
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "fa2694a9-83fb-4143-a82a-737f2db7d8c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T08:57:21.409275Z",
     "start_time": "2024-07-31T08:57:21.406943Z"
    }
   },
   "source": [],
   "execution_count": 12,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
