{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e75e26fe-8e49-4ff9-858f-c3d821d17bcb",
   "metadata": {},
   "source": [
    "import os\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "from botorch.acquisition import qExpectedImprovement\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.generation import MaxPosteriorSampling\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.test_functions import Ackley\n",
    "from botorch.utils.transforms import unnormalize\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "import gpytorch\n",
    "from gpytorch.constraints import Interval\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.priors import HorseshoePrior\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93dceaf5-d5ea-48b3-a771-c9ee09d4008a",
   "metadata": {},
   "source": [
    "'''fun = Ackley(dim=20, negate=True).to(dtype=dtype, device=device)\n",
    "fun.bounds[0, :].fill_(-5)\n",
    "fun.bounds[1, :].fill_(10)\n",
    "dim = fun.dim\n",
    "lb, ub = fun.bounds\n",
    "\n",
    "batch_size = 4\n",
    "n_init = 2 * dim\n",
    "max_cholesky_size = float(\"inf\")  # Always use Cholesky\n",
    "\n",
    "\n",
    "def eval_objective(x):\n",
    "    \"\"\"This is a helper function we use to unnormalize and evalaute a point\"\"\"\n",
    "    return fun(unnormalize(x, fun.bounds))'''"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8222d64b",
   "metadata": {},
   "source": [
    "import torch\n",
    "from typing import List, Tuple, Optional\n",
    "from torch import Tensor\n",
    "from torch.distributions import Distribution\n",
    "from botorch.test_functions.synthetic import SyntheticTestFunction\n",
    "\n",
    "\n",
    "\n",
    "class myFunction(SyntheticTestFunction):\n",
    "\n",
    "    _optimal_value = 0.0\n",
    "    _check_grad_at_opt: bool = False\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int = 2,\n",
    "        noise_std: Optional[float] = None,\n",
    "        negate: bool = False,\n",
    "        bounds: Optional[List[Tuple[float, float]]] = None,\n",
    "    ) -> None:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            dim: The (input) dimension.\n",
    "            noise_std: Standard deviation of the observation noise.\n",
    "            negate: If True, negate the function.\n",
    "            bounds: Custom bounds for the function specified as (lower, upper) pairs.\n",
    "        \"\"\"\n",
    "        self.dim = dim\n",
    "        if bounds is None:\n",
    "            bounds = [(-32.768, 32.768) for _ in range(self.dim)]\n",
    "        self._optimizers = [tuple(0.0 for _ in range(self.dim))]\n",
    "        super().__init__(noise_std=noise_std, negate=negate, bounds=bounds)\n",
    "\n",
    "\n",
    "    def evaluate_true(self, X: Tensor) -> Tensor:\n",
    "        # Get values at odd indices\n",
    "        X_odd = X[:, 0::2]  # Start from index 0, take every second element\n",
    "        # Get values at even indices\n",
    "        X_even = X[:, 1::2]  # Start from index 1, take every second element\n",
    "\n",
    "        # Compute sin for odd indices\n",
    "        part1 = torch.sin(X_odd.sum(dim=-1, keepdim=True))\n",
    "        # Compute cos for even indices\n",
    "        part2 = torch.cos(X_even.sum(dim=-1, keepdim=True))\n",
    "        print(X_odd.shape)\n",
    "        print(X_even.shape)\n",
    "        result = torch.cat((part1, part2), dim=-1)\n",
    "        print(result.shape)\n",
    "        \n",
    "        print(X_odd)\n",
    "        print(X_even)\n",
    "        \n",
    "        return result"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7c381f7",
   "metadata": {},
   "source": [
    "#fun = Ackley(dim=20, negate=True).to(dtype=dtype, device=device)\n",
    "fun = myFunction(dim = 2, negate = True).to(dtype=dtype, device = device)\n",
    "fun.bounds[0, :].fill_(-5)\n",
    "fun.bounds[1, :].fill_(10)\n",
    "dim = fun.dim\n",
    "lb, ub = fun.bounds\n",
    "\n",
    "batch_size = 4\n",
    "n_init = 2 * dim\n",
    "max_cholesky_size = float(\"inf\")  # Always use Cholesky\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def eval_objective(x):\n",
    "    \"\"\"This is a helper function we use to unnormalize and evaluate a point\"\"\"\n",
    "    # Unnormalize the input\n",
    "    x_unnormalized = unnormalize(x, fun.bounds)\n",
    "    # Apply the constraint for x1 and x3 separately\n",
    "    #constraint_x1 = torch.where((x_unnormalized[:, 0] >= 1) & (x_unnormalized[:, 0] <= 3), torch.zeros(1, device=x.device), 1e6 * torch.ones(1, device=x.device))\n",
    "    #constraint_x2 = torch.where((x_unnormalized[:, 2] >= -4) & (x_unnormalized[:, 2] <= -2), torch.zeros(1, device=x.device), 1e6 * torch.ones(1, device=x.device))\n",
    "    # Penalty for violating the constraints\n",
    "    #penalty = constraint_x1 + constraint_x3\n",
    "    # Enforce box constraints by projecting points outside the bounds back onto the bounds\n",
    "    # x_constrained = torch.min(torch.max(x_unnormalized, fun.bounds[0]), fun.bounds[1])\n",
    "    # Evaluate the function with box constraints and add the penalty\n",
    "    return fun(x_unnormalized) #+ penalty\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb23296b-c804-4341-9aa2-9a99fee9b10a",
   "metadata": {},
   "source": [
    "@dataclass\n",
    "class TurboState:\n",
    "    dim: int\n",
    "    batch_size: int\n",
    "    length: float = 0.8\n",
    "    length_min: float = 0.5**7\n",
    "    length_max: float = 1.6\n",
    "    failure_counter: int = 0\n",
    "    failure_tolerance: int = float(\"nan\")  # Note: Post-initialized\n",
    "    success_counter: int = 0\n",
    "    success_tolerance: int = 10  # Note: The original paper uses 3\n",
    "    best_value: float = -float(\"inf\")\n",
    "    restart_triggered: bool = False\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.failure_tolerance = math.ceil(\n",
    "            max([4.0 / self.batch_size, float(self.dim) / self.batch_size])\n",
    "        )\n",
    "\n",
    "\n",
    "def update_state(state, Y_next):\n",
    "    if max(Y_next) > state.best_value + 1e-3 * math.fabs(state.best_value):\n",
    "        state.success_counter += 1\n",
    "        state.failure_counter = 0\n",
    "    else:\n",
    "        state.success_counter = 0\n",
    "        state.failure_counter += 1\n",
    "\n",
    "    if state.success_counter == state.success_tolerance:  # Expand trust region\n",
    "        state.length = min(2.0 * state.length, state.length_max)\n",
    "        state.success_counter = 0\n",
    "    elif state.failure_counter == state.failure_tolerance:  # Shrink trust region\n",
    "        state.length /= 2.0\n",
    "        state.failure_counter = 0\n",
    "\n",
    "    state.best_value = max(state.best_value, max(Y_next).item())\n",
    "    if state.length < state.length_min:\n",
    "        state.restart_triggered = True\n",
    "    return state"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b338f71b-01d5-4915-b6cd-5fbc8c35be8b",
   "metadata": {},
   "source": [
    "state = TurboState(dim=dim, batch_size=batch_size)\n",
    "print(state)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a69c695-a1bb-46ab-afdb-f24473aeb6be",
   "metadata": {},
   "source": [
    "def get_initial_points(dim, n_pts, seed=0):\n",
    "    sobol = SobolEngine(dimension=dim, scramble=True, seed=seed)\n",
    "    X_init = sobol.draw(n=n_pts).to(dtype=dtype, device=device)\n",
    "    return X_init"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6626c5f1-bba6-407d-8bfa-425a5a03c94e",
   "metadata": {},
   "source": [
    "def generate_batch(\n",
    "    state,\n",
    "    model,  # GP model\n",
    "    X,  # Evaluated points on the domain [0, 1]^d\n",
    "    Y,  # Function values\n",
    "    batch_size,\n",
    "    n_candidates=None,  # Number of candidates for Thompson sampling\n",
    "    num_restarts=10,\n",
    "    raw_samples=512,\n",
    "    acqf=\"ts\",  # \"ei\" or \"ts\"\n",
    "):\n",
    "    assert acqf in (\"ts\", \"ei\")\n",
    "    assert X.min() >= 0.0 and X.max() <= 1.0 and torch.all(torch.isfinite(Y))\n",
    "    if n_candidates is None:\n",
    "        n_candidates = min(5000, max(2000, 200 * X.shape[-1]))\n",
    "\n",
    "    # Scale the TR to be proportional to the lengthscales\n",
    "    x_center = X[Y.argmax(), :].clone()\n",
    "    weights = model.covar_module.base_kernel.lengthscale.squeeze().detach()\n",
    "    weights = weights / weights.mean()\n",
    "    weights = weights / torch.prod(weights.pow(1.0 / len(weights)))\n",
    "    tr_lb = torch.clamp(x_center - weights * state.length / 2.0, 0.0, 1.0)\n",
    "    tr_ub = torch.clamp(x_center + weights * state.length / 2.0, 0.0, 1.0)\n",
    "\n",
    "    if acqf == \"ts\":\n",
    "        dim = X.shape[-1]\n",
    "        sobol = SobolEngine(dim, scramble=True)\n",
    "        pert = sobol.draw(n_candidates).to(dtype=dtype, device=device)\n",
    "        pert = tr_lb + (tr_ub - tr_lb) * pert\n",
    "\n",
    "        # Create a perturbation mask\n",
    "        prob_perturb = min(20.0 / dim, 1.0)\n",
    "        mask = torch.rand(n_candidates, dim, dtype=dtype, device=device) <= prob_perturb\n",
    "        ind = torch.where(mask.sum(dim=1) == 0)[0]\n",
    "        mask[ind, torch.randint(0, dim - 1, size=(len(ind),), device=device)] = 1\n",
    "\n",
    "        # Create candidate points from the perturbations and the mask\n",
    "        X_cand = x_center.expand(n_candidates, dim).clone()\n",
    "        X_cand[mask] = pert[mask]\n",
    "\n",
    "        # Sample on the candidate points\n",
    "        thompson_sampling = MaxPosteriorSampling(model=model, replacement=False)\n",
    "        with torch.no_grad():  # We don't need gradients when using TS\n",
    "            X_next = thompson_sampling(X_cand, num_samples=batch_size)\n",
    "\n",
    "    elif acqf == \"ei\":\n",
    "        ei = qExpectedImprovement(model, train_Y.max())\n",
    "        X_next, acq_value = optimize_acqf(\n",
    "            ei,\n",
    "            bounds=torch.stack([tr_lb, tr_ub]),\n",
    "            q=batch_size,\n",
    "            num_restarts=num_restarts,\n",
    "            raw_samples=raw_samples,\n",
    "        )\n",
    "\n",
    "    return X_next"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a20ecd16-1b13-4eea-bd20-d72548484bb9",
   "metadata": {},
   "source": [
    "X_turbo = get_initial_points(dim, n_init)\n",
    "Y_turbo = torch.tensor(\n",
    "    eval_objective(X_turbo), dtype=dtype, device=device\n",
    ").unsqueeze(-1)\n",
    "print(Y_turbo.shape)\n",
    "print(Y_turbo)\n",
    "state = TurboState(dim, batch_size=batch_size)\n",
    "\n",
    "NUM_RESTARTS = 10 if not SMOKE_TEST else 2\n",
    "RAW_SAMPLES = 512 if not SMOKE_TEST else 4\n",
    "N_CANDIDATES = min(5000, max(2000, 200 * dim)) if not SMOKE_TEST else 4\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "while not state.restart_triggered:  # Run until TuRBO converges\n",
    "    # Fit a GP model\n",
    "    train_Y = (Y_turbo - Y_turbo.mean()) / Y_turbo.std()\n",
    "    likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
    "    covar_module = ScaleKernel(  # Use the same lengthscale prior as in the TuRBO paper\n",
    "        MaternKernel(\n",
    "            nu=2.5, ard_num_dims=dim, lengthscale_constraint=Interval(0.005, 4.0)\n",
    "        )\n",
    "    )\n",
    "    model = SingleTaskGP(\n",
    "        X_turbo, train_Y, covar_module=covar_module, likelihood=likelihood\n",
    "    )\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "    # Do the fitting and acquisition function optimization inside the Cholesky context\n",
    "    with gpytorch.settings.max_cholesky_size(max_cholesky_size):\n",
    "        # Fit the model\n",
    "        fit_gpytorch_mll(mll)\n",
    "\n",
    "        # Create a batch\n",
    "        X_next = generate_batch(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            X=X_turbo,\n",
    "            Y=train_Y,\n",
    "            batch_size=batch_size,\n",
    "            n_candidates=N_CANDIDATES,\n",
    "            num_restarts=NUM_RESTARTS,\n",
    "            raw_samples=RAW_SAMPLES,\n",
    "            acqf=\"ts\",\n",
    "        )\n",
    "\n",
    "    Y_next = torch.tensor(\n",
    "        eval_objective(X_next), dtype=dtype, device=device\n",
    "    ).unsqueeze(-1)\n",
    "\n",
    "\n",
    "    # Update state\n",
    "    state = update_state(state=state, Y_next=Y_next)\n",
    "\n",
    "    # Append data\n",
    "    X_turbo = torch.cat((X_turbo, X_next), dim=0)\n",
    "    Y_turbo = torch.cat((Y_turbo, Y_next), dim=0)\n",
    "\n",
    "\n",
    "    # Print current status\n",
    "    print(\n",
    "        f\"{len(X_turbo)}) Best value: {state.best_value:.2e}, TR length: {state.length:.2e}\"\n",
    "    )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3d3b8c-b7d3-4f45-bc59-bd697b8fd979",
   "metadata": {},
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "X_ei = get_initial_points(dim, n_init)\n",
    "Y_ei = torch.tensor(\n",
    "    eval_objective(X_ei), dtype=dtype, device=device\n",
    ").unsqueeze(-1)\n",
    "\n",
    "while len(Y_ei) < len(Y_turbo):\n",
    "    train_Y = (Y_ei - Y_ei.mean()) / Y_ei.std()\n",
    "    likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
    "    model = SingleTaskGP(X_ei, train_Y, likelihood=likelihood)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "\n",
    "    # Create a batch\n",
    "    ei = qExpectedImprovement(model, train_Y.max())\n",
    "    candidate, acq_value = optimize_acqf(\n",
    "        ei,\n",
    "        bounds=torch.stack(\n",
    "            [\n",
    "                torch.zeros(dim, dtype=dtype, device=device),\n",
    "                torch.ones(dim, dtype=dtype, device=device),\n",
    "            ]\n",
    "        ),\n",
    "        q=batch_size,\n",
    "        num_restarts=NUM_RESTARTS,\n",
    "        raw_samples=RAW_SAMPLES,\n",
    "    )\n",
    "    Y_next = torch.tensor(\n",
    "        eval_objective(candidate), dtype=dtype, device=device\n",
    "    ).unsqueeze(-1)\n",
    "\n",
    "    # Append data\n",
    "    X_ei = torch.cat((X_ei, candidate), axis=0)\n",
    "    Y_ei = torch.cat((Y_ei, Y_next), axis=0)\n",
    "\n",
    "    # Print current status\n",
    "    print(f\"{len(X_ei)}) Best value: {Y_ei.max().item():.2e}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fcdf24-3a46-45b8-9054-c4fa8c1b5308",
   "metadata": {},
   "source": [
    "X_Sobol = (\n",
    "    SobolEngine(dim, scramble=True, seed=0)\n",
    "    .draw(len(X_turbo))\n",
    "    .to(dtype=dtype, device=device)\n",
    ")\n",
    "Y_Sobol = torch.tensor(\n",
    "    eval_objective(X_Sobol), dtype=dtype, device=device\n",
    ").unsqueeze(-1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b263a9-b08a-4e8e-8c36-3f8b1698719c",
   "metadata": {},
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import rc\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "names = [\"TuRBO-1\", \"EI\", \"Sobol\"]\n",
    "runs = [Y_turbo, Y_ei, Y_Sobol]\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "for name, run in zip(names, runs):\n",
    "    fx = np.maximum.accumulate(run.cpu())\n",
    "    plt.plot(fx, marker=\"\", lw=3)\n",
    "\n",
    "plt.plot([0, len(Y_turbo)], [fun.optimal_value, fun.optimal_value], \"k--\", lw=3)\n",
    "plt.xlabel(\"Function value\", fontsize=18)\n",
    "plt.xlabel(\"Number of evaluations\", fontsize=18)\n",
    "plt.title(\"20D Ackley\", fontsize=24)\n",
    "plt.xlim([0, len(Y_turbo)])\n",
    "plt.ylim([-15, 1])\n",
    "\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.legend(\n",
    "    names + [\"Global optimal value\"],\n",
    "    loc=\"lower center\",\n",
    "    bbox_to_anchor=(0, -0.08, 1, 1),\n",
    "    bbox_transform=plt.gcf().transFigure,\n",
    "    ncol=4,\n",
    "    fontsize=16,\n",
    ")\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f24ed3",
   "metadata": {},
   "source": [
    "'''# Define your objective function (replace this with your actual function)\n",
    "def f(x):\n",
    "    return (x - 0.5).sin()  # Example function\n",
    "\n",
    "# Define the bounds of the input space\n",
    "lb = torch.zeros(10)  # Lower bounds\n",
    "ub = torch.ones(10)   # Upper bounds\n",
    "\n",
    "# Initial dataset (replace this with your actual initial dataset)\n",
    "X = torch.rand(5, 10)  # 5 initial input points\n",
    "Y = f(X)  # Corresponding function values\n",
    "\n",
    "# Initialize Turbo1 instance\n",
    "turbo = Turbo1(f=f, lb=lb, ub=ub, n_init=10, max_evals=200, batch_size=5, verbose=True)\n",
    "\n",
    "# Compute optimization\n",
    "X_opt, Y_opt = turbo.optimize()\n",
    "\n",
    "# Print results\n",
    "print(\"Optimized input points (X):\")\n",
    "print(X_opt)\n",
    "print(\"Corresponding function values (Y):\")\n",
    "print(Y_opt)\n",
    "'''"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff44db3",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b9a43",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b878c3a-8d12-4a32-b14f-a5293950fbeb",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
