{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e75e26fe-8e49-4ff9-858f-c3d821d17bcb",
   "metadata": {},
   "source": [
    "import os\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "from botorch.acquisition import qExpectedImprovement\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.generation import MaxPosteriorSampling\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.test_functions import Ackley\n",
    "from botorch.utils.transforms import unnormalize\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "import gpytorch\n",
    "from gpytorch.constraints import Interval\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.priors import HorseshoePrior\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93dceaf5-d5ea-48b3-a771-c9ee09d4008a",
   "metadata": {},
   "source": [
    "fun = Ackley(dim=20, negate=True).to(dtype=dtype, device=device)\n",
    "fun.bounds[0, :].fill_(-5)\n",
    "fun.bounds[1, :].fill_(10)\n",
    "dim = fun.dim\n",
    "lb, ub = fun.bounds\n",
    "\n",
    "batch_size = 4\n",
    "n_init = 2 * dim\n",
    "max_cholesky_size = float(\"inf\")  # Always use Cholesky\n",
    "\n",
    "\n",
    "def eval_objective(x):\n",
    "    \"\"\"This is a helper function we use to unnormalize and evalaute a point\"\"\"\n",
    "    return fun(unnormalize(x, fun.bounds))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb23296b-c804-4341-9aa2-9a99fee9b10a",
   "metadata": {},
   "source": [
    "@dataclass\n",
    "class TurboState:\n",
    "    dim: int\n",
    "    batch_size: int\n",
    "    length: float = 0.8\n",
    "    length_min: float = 0.5**7\n",
    "    length_max: float = 1.6\n",
    "    failure_counter: int = 0\n",
    "    failure_tolerance: int = float(\"nan\")  # Note: Post-initialized\n",
    "    success_counter: int = 0\n",
    "    success_tolerance: int = 10  # Note: The original paper uses 3\n",
    "    best_value: float = -float(\"inf\")\n",
    "    restart_triggered: bool = False\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.failure_tolerance = math.ceil(\n",
    "            max([4.0 / self.batch_size, float(self.dim) / self.batch_size])\n",
    "        )\n",
    "\n",
    "\n",
    "def update_state(state, Y_next):\n",
    "    if max(Y_next) > state.best_value + 1e-3 * math.fabs(state.best_value):\n",
    "        state.success_counter += 1\n",
    "        state.failure_counter = 0\n",
    "    else:\n",
    "        state.success_counter = 0\n",
    "        state.failure_counter += 1\n",
    "\n",
    "    if state.success_counter == state.success_tolerance:  # Expand trust region\n",
    "        state.length = min(2.0 * state.length, state.length_max)\n",
    "        state.success_counter = 0\n",
    "    elif state.failure_counter == state.failure_tolerance:  # Shrink trust region\n",
    "        state.length /= 2.0\n",
    "        state.failure_counter = 0\n",
    "\n",
    "    state.best_value = max(state.best_value, max(Y_next).item())\n",
    "    if state.length < state.length_min:\n",
    "        state.restart_triggered = True\n",
    "    return state"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b338f71b-01d5-4915-b6cd-5fbc8c35be8b",
   "metadata": {},
   "source": [
    "state = TurboState(dim=dim, batch_size=batch_size)\n",
    "print(state)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a69c695-a1bb-46ab-afdb-f24473aeb6be",
   "metadata": {},
   "source": [
    "def get_initial_points(dim, n_pts, seed=0):\n",
    "    sobol = SobolEngine(dimension=dim, scramble=True, seed=seed)\n",
    "    X_init = sobol.draw(n=n_pts).to(dtype=dtype, device=device)\n",
    "    return X_init"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6626c5f1-bba6-407d-8bfa-425a5a03c94e",
   "metadata": {},
   "source": [
    "def generate_batch(\n",
    "    state,\n",
    "    model,  # GP model\n",
    "    X,  # Evaluated points on the domain [0, 1]^d\n",
    "    Y,  # Function values\n",
    "    batch_size,\n",
    "    n_candidates=None,  # Number of candidates for Thompson sampling\n",
    "    num_restarts=10,\n",
    "    raw_samples=512,\n",
    "    acqf=\"ts\",  # \"ei\" or \"ts\"\n",
    "):\n",
    "    assert acqf in (\"ts\", \"ei\")\n",
    "    assert X.min() >= 0.0 and X.max() <= 1.0 and torch.all(torch.isfinite(Y))\n",
    "    if n_candidates is None:\n",
    "        n_candidates = min(5000, max(2000, 200 * X.shape[-1]))\n",
    "\n",
    "    # Scale the TR to be proportional to the lengthscales\n",
    "    x_center = X[Y.argmax(), :].clone()\n",
    "    weights = model.covar_module.base_kernel.lengthscale.squeeze().detach()\n",
    "    weights = weights / weights.mean()\n",
    "    weights = weights / torch.prod(weights.pow(1.0 / len(weights)))\n",
    "    tr_lb = torch.clamp(x_center - weights * state.length / 2.0, 0.0, 1.0)\n",
    "    tr_ub = torch.clamp(x_center + weights * state.length / 2.0, 0.0, 1.0)\n",
    "\n",
    "    if acqf == \"ts\":\n",
    "        dim = X.shape[-1]\n",
    "        sobol = SobolEngine(dim, scramble=True)\n",
    "        pert = sobol.draw(n_candidates).to(dtype=dtype, device=device)\n",
    "        pert = tr_lb + (tr_ub - tr_lb) * pert\n",
    "\n",
    "        # Create a perturbation mask\n",
    "        prob_perturb = min(20.0 / dim, 1.0)\n",
    "        mask = torch.rand(n_candidates, dim, dtype=dtype, device=device) <= prob_perturb\n",
    "        ind = torch.where(mask.sum(dim=1) == 0)[0]\n",
    "        mask[ind, torch.randint(0, dim - 1, size=(len(ind),), device=device)] = 1\n",
    "\n",
    "        # Create candidate points from the perturbations and the mask\n",
    "        X_cand = x_center.expand(n_candidates, dim).clone()\n",
    "        X_cand[mask] = pert[mask]\n",
    "\n",
    "        # Sample on the candidate points\n",
    "        thompson_sampling = MaxPosteriorSampling(model=model, replacement=False)\n",
    "        with torch.no_grad():  # We don't need gradients when using TS\n",
    "            X_next = thompson_sampling(X_cand, num_samples=batch_size)\n",
    "\n",
    "    elif acqf == \"ei\":\n",
    "        ei = qExpectedImprovement(model, train_Y.max())\n",
    "        X_next, acq_value = optimize_acqf(\n",
    "            ei,\n",
    "            bounds=torch.stack([tr_lb, tr_ub]),\n",
    "            q=batch_size,\n",
    "            num_restarts=num_restarts,\n",
    "            raw_samples=raw_samples,\n",
    "        )\n",
    "\n",
    "    return X_next"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20ecd16-1b13-4eea-bd20-d72548484bb9",
   "metadata": {},
   "source": [
    "X_turbo = get_initial_points(dim, n_init)\n",
    "Y_turbo = torch.tensor(\n",
    "    [eval_objective(x) for x in X_turbo], dtype=dtype, device=device\n",
    ").unsqueeze(-1)\n",
    "\n",
    "state = TurboState(dim, batch_size=batch_size)\n",
    "\n",
    "NUM_RESTARTS = 10 if not SMOKE_TEST else 2\n",
    "RAW_SAMPLES = 512 if not SMOKE_TEST else 4\n",
    "N_CANDIDATES = min(5000, max(2000, 200 * dim)) if not SMOKE_TEST else 4\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "while not state.restart_triggered:  # Run until TuRBO converges\n",
    "    # Fit a GP model\n",
    "    train_Y = (Y_turbo - Y_turbo.mean()) / Y_turbo.std()\n",
    "    likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
    "    covar_module = ScaleKernel(  # Use the same lengthscale prior as in the TuRBO paper\n",
    "        MaternKernel(\n",
    "            nu=2.5, ard_num_dims=dim, lengthscale_constraint=Interval(0.005, 4.0)\n",
    "        )\n",
    "    )\n",
    "    model = SingleTaskGP(\n",
    "        X_turbo, train_Y, covar_module=covar_module, likelihood=likelihood\n",
    "    )\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "    # Do the fitting and acquisition function optimization inside the Cholesky context\n",
    "    with gpytorch.settings.max_cholesky_size(max_cholesky_size):\n",
    "        # Fit the model\n",
    "        fit_gpytorch_mll(mll)\n",
    "\n",
    "        # Create a batch\n",
    "        X_next = generate_batch(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            X=X_turbo,\n",
    "            Y=train_Y,\n",
    "            batch_size=batch_size,\n",
    "            n_candidates=N_CANDIDATES,\n",
    "            num_restarts=NUM_RESTARTS,\n",
    "            raw_samples=RAW_SAMPLES,\n",
    "            acqf=\"ts\",\n",
    "        )\n",
    "\n",
    "    Y_next = torch.tensor(\n",
    "        [eval_objective(x) for x in X_next], dtype=dtype, device=device\n",
    "    ).unsqueeze(-1)\n",
    "\n",
    "    # Update state\n",
    "    state = update_state(state=state, Y_next=Y_next)\n",
    "\n",
    "    # Append data\n",
    "    X_turbo = torch.cat((X_turbo, X_next), dim=0)\n",
    "    Y_turbo = torch.cat((Y_turbo, Y_next), dim=0)\n",
    "\n",
    "    # Print current status\n",
    "    print(\n",
    "        f\"{len(X_turbo)}) Best value: {state.best_value:.2e}, TR length: {state.length:.2e}\"\n",
    "    )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3d3b8c-b7d3-4f45-bc59-bd697b8fd979",
   "metadata": {},
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "X_ei = get_initial_points(dim, n_init)\n",
    "Y_ei = torch.tensor(\n",
    "    [eval_objective(x) for x in X_ei], dtype=dtype, device=device\n",
    ").unsqueeze(-1)\n",
    "\n",
    "while len(Y_ei) < len(Y_turbo):\n",
    "    train_Y = (Y_ei - Y_ei.mean()) / Y_ei.std()\n",
    "    likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
    "    model = SingleTaskGP(X_ei, train_Y, likelihood=likelihood)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "\n",
    "    # Create a batch\n",
    "    ei = qExpectedImprovement(model, train_Y.max())\n",
    "    candidate, acq_value = optimize_acqf(\n",
    "        ei,\n",
    "        bounds=torch.stack(\n",
    "            [\n",
    "                torch.zeros(dim, dtype=dtype, device=device),\n",
    "                torch.ones(dim, dtype=dtype, device=device),\n",
    "            ]\n",
    "        ),\n",
    "        q=batch_size,\n",
    "        num_restarts=NUM_RESTARTS,\n",
    "        raw_samples=RAW_SAMPLES,\n",
    "    )\n",
    "    Y_next = torch.tensor(\n",
    "        [eval_objective(x) for x in candidate], dtype=dtype, device=device\n",
    "    ).unsqueeze(-1)\n",
    "\n",
    "    # Append data\n",
    "    X_ei = torch.cat((X_ei, candidate), axis=0)\n",
    "    Y_ei = torch.cat((Y_ei, Y_next), axis=0)\n",
    "\n",
    "    # Print current status\n",
    "    print(f\"{len(X_ei)}) Best value: {Y_ei.max().item():.2e}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fcdf24-3a46-45b8-9054-c4fa8c1b5308",
   "metadata": {},
   "source": [
    "X_Sobol = (\n",
    "    SobolEngine(dim, scramble=True, seed=0)\n",
    "    .draw(len(X_turbo))\n",
    "    .to(dtype=dtype, device=device)\n",
    ")\n",
    "Y_Sobol = torch.tensor(\n",
    "    [eval_objective(x) for x in X_Sobol], dtype=dtype, device=device\n",
    ").unsqueeze(-1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32b263a9-b08a-4e8e-8c36-3f8b1698719c",
   "metadata": {},
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import rc\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "names = [\"TuRBO-1\", \"EI\", \"Sobol\"]\n",
    "runs = [Y_turbo, Y_ei, Y_Sobol]\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "for name, run in zip(names, runs):\n",
    "    fx = np.maximum.accumulate(run.cpu())\n",
    "    plt.plot(fx, marker=\"\", lw=3)\n",
    "\n",
    "plt.plot([0, len(Y_turbo)], [fun.optimal_value, fun.optimal_value], \"k--\", lw=3)\n",
    "plt.xlabel(\"Function value\", fontsize=18)\n",
    "plt.xlabel(\"Number of evaluations\", fontsize=18)\n",
    "plt.title(\"20D Ackley\", fontsize=24)\n",
    "plt.xlim([0, len(Y_turbo)])\n",
    "plt.ylim([-15, 1])\n",
    "\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.legend(\n",
    "    names + [\"Global optimal value\"],\n",
    "    loc=\"lower center\",\n",
    "    bbox_to_anchor=(0, -0.08, 1, 1),\n",
    "    bbox_transform=plt.gcf().transFigure,\n",
    "    ncol=4,\n",
    "    fontsize=16,\n",
    ")\n",
    "plt.show()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
